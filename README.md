mindmap
  root(因果推理与大模型：理论、方法与应用)
    1 核心论点与背景
      1.1 当前AI的根本局限
        : 数据驱动的**关联学习**
        : 无法区分因果与虚假关联
      1.2 后果
        : **不可解释性** (e.g., “草地”预测“狗”)
        : **不可决策性** (e.g., 关联无法指导行动)
        : **不稳定/不鲁棒** (分布外泛化差)
        : **不公平性** (数据偏差放大社会偏见)
      1.3 因果推理的价值
        : 从“知其然”(关联)到“**知其所以然**”(因果)
        : 实现稳健、可解释、可决策的下一代AI
    2 因果推理基础与前沿方法
      2.1 核心理论与目标
        : 定义: 控制其他变量不变，改变T，观察Y的变化
        : 目标: 评估干预(T)对结果(Y)的**因果效应**
        : 黄金标准: **随机对照实验** (RCT/A/B测试)
      2.2 基于观测数据的因果推断
        : 核心挑战: **混杂偏差** (混淆变量X影响T和Y)
        2.2.1 经典方法
          : **匹配法** (精确匹配、倾向得分匹配)
          : **倾向得分加权** (IPW)
          : **双稳健估计**
        2.2.2 前沿探索
          : **直接平衡表征** (学习样本权重使分布一致)
          : **处理复杂偏差** (混淆+选择偏差并存)
          : **处理复杂干预** (高维、连续型干预变量)
    3 因果启发的稳定机器学习
      3.1 问题定义: **稳定预测**
        : 目标: 从单训练分布中学到模型，在未知测试分布上稳定预测
        : 根源: 模型学到了**虚假关联**特征(如“草地”)
      3.2 核心方法: **解耦因果与虚假特征**
        : 思想: 施加**因果约束**，使任意特征间相互独立
        : 实现: 学习样本权重，加权训练模型
        : 效果: 抑制虚假特征，模型更依赖因果特征，提升分布外鲁棒性
    4 因果推理赋能大语言模型
      4.1 诊断: LLMs本质仍是关联学习
        : Transformer的Attention机制在学习**token间的关联**
        : 导致幻觉、脆弱性、偏见等问题
      4.2 赋能路径
        4.2.1 架构层面 (Pre-training)
          : 设计**Causal Transformer**: 让Attention学习因果而非关联
          : **因果知识增强**: 用外部因果图约束Attention矩阵
        4.2.2 微调层面 (SFT)
          : **因果去偏差**: 消除小样本指令数据中的虚假关联
        4.2.3 对齐层面 (RLHF)
          : **因果强化学习**: 更可靠地评估人类偏好，支撑决策
    5 因果推理赋能结构化数据大模型
      5.1 新范式: **大数模 (Large Data Model)**
        : 定位: 面向表格/时序等**结构化数据**的通用基础模型
        : 目标: 实现**零样本/上下文学习**的精准预测与推理
        : 核心: 学习数据中的**因果规律**，而非简单拟合
      5.2 关键实现: Lynx模型
        : 预训练数据: 海量**因果模型生成的仿真数据**
        : 核心任务: **掩码建模** (学习变量联合分布)
        : 模型架构: 改进的Transformer (特征/样本双维度Attention)
        : 核心能力: 通过Attention机制**自动选择关键特征与样本**
    6 因果推理赋能具身智能与大模型
      6.1 核心理念
        : 与环境的**交互**（行动与反馈）本质上是**干预**
        : 干预数据能极大增强因果发现与估计能力
      6.2 理论支撑
        : **定理**: 能在多环境中实现最优策略的智能体，必然学到了环境的因果模型。
        : **推论**: 因果模型是实现泛化性**具身智能**的必要条件。
      6.3 研究展望
        : 构建评测基准: 检验智能体是否通过交互学到因果知识
        : 探索架构: 将因果世界模型与大模型驱动智能体结合

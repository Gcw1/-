import cv2
import numpy as np
from tensorflow import keras
import os
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
import pandas as pd
import math

# ===================== 1. æ ¸å¿ƒé…ç½®å‚æ•° =====================
MODEL_PATH = r"D:\OneDrive\æ¡Œé¢\Traffic_Sign_Classify\Mymodle\traffic_sign_model.h5"
CLASS_NAMES = [
    "é™é€Ÿ20km/h", "é™é€Ÿ30km/h", "é™é€Ÿ50km/h", "é™é€Ÿ60km/h", "é™é€Ÿ70km/h",
    "é™é€Ÿ80km/h", "è§£é™¤é™é€Ÿ80km/h", "é™é€Ÿ100km/h", "é™é€Ÿ120km/h", "ç¦æ­¢è¶…è½¦",
    "ç¦æ­¢å¤§å‹è½¦è¾†è¶…è½¦", "å‰æ–¹è·¯å£", "ä¼˜å…ˆé€šè¡Œ", "è®©è¡Œ", "åœè½¦è®©è¡Œ",
    "ç¦æ­¢é€šè¡Œ", "ç¦æ­¢å¤§å‹è½¦è¾†è¿›å…¥", "ç¦æ­¢é©¶å…¥", "è­¦å‘Š", "æ€¥è½¬å¼¯ï¼ˆå·¦ï¼‰",
    "æ€¥è½¬å¼¯ï¼ˆå³ï¼‰", "è¿ç»­å¼¯é“", "è·¯é¢é¢ ç°¸", "è·¯é¢æ¹¿æ»‘", "é“è·¯å˜çª„ï¼ˆå³ï¼‰",
    "æ–½å·¥", "äº¤é€šä¿¡å·ç¯", "è¡Œäºº", "å„¿ç«¥", "è‡ªè¡Œè½¦",
    "é“è·¯ç»“å†°", "é‡ç”ŸåŠ¨ç‰©", "è§£é™¤é™é€Ÿ/è¶…è½¦", "å³è½¬", "å·¦è½¬",
    "ç›´è¡Œ", "ç›´è¡Œ+å³è½¬", "ç›´è¡Œ+å·¦è½¬", "é å³è¡Œé©¶", "é å·¦è¡Œé©¶",
    "ç¯å²›è¡Œé©¶", "è§£é™¤ç¦æ­¢è¶…è½¦", "è§£é™¤ç¦æ­¢å¤§å‹è½¦è¾†è¶…è½¦"
]
INPUT_SIZE = (32, 32)
FONT_PATH = r"C:\Windows\Fonts\msyh.ttc"

# ===================== æ‰¹é‡å¤„ç†+æŒ‡æ ‡é…ç½® =====================
INPUT_FOLDER = r"D:\OneDrive\æ¡Œé¢\æ–°å»ºæ–‡ä»¶å¤¹ (4)"
OUTPUT_FOLDER = r"D:\OneDrive\æ¡Œé¢\æ–°å»ºæ–‡ä»¶å¤¹ (4)\è¯†åˆ«ç»“æœ"
SUPPORTED_FORMATS = ('.ppm', '.png', '.jpg', '.jpeg', '.bmp')

# æŒ‡æ ‡é…ç½®
LOW_CONFIDENCE_THRESHOLD = 80.0  # ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼æ ‡è®°é¢„è­¦ï¼‰
REPORT_SAVE_PATH = os.path.join(OUTPUT_FOLDER, "æ‰¹é‡è¯†åˆ«æŒ‡æ ‡æŠ¥å‘Š.csv")
METRICS_TXT_PATH = os.path.join(OUTPUT_FOLDER, "æ‰¹é‡è¯†åˆ«æŒ‡æ ‡æ±‡æ€».txt")
PLOT_SAVE_PATH = os.path.join(OUTPUT_FOLDER, "è¯†åˆ«æŒ‡æ ‡å¯è§†åŒ–.png")

# ä¸­æ–‡æ˜¾ç¤ºé…ç½®
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False


# ===================== 2. å·¥å…·å‡½æ•°å®šä¹‰ =====================
def read_ppm_manually(file_path):
    try:
        with open(file_path, 'rb') as f:
            header = f.readline().decode('ascii').strip()
            if header not in ('P3', 'P6'):
                return None
            while True:
                line = f.readline().decode('ascii').strip()
                if not line.startswith('#'):
                    break
            width, height = map(int, line.split())
            max_val = int(f.readline().decode('ascii').strip())
            if header == 'P6':
                data = f.read(width * height * 3)
                img = np.frombuffer(data, dtype=np.uint8).reshape((height, width, 3))
            else:
                data = []
                while len(data) < width * height * 3:
                    data += list(map(int, f.readline().decode('ascii').split()))
                img = np.array(data, dtype=np.uint8).reshape((height, width, 3))
        return img
    except Exception as e:
        print(f"è¯»å–{file_path}å¤±è´¥ï¼š{e}")
        return None


def preprocess_image(img):
    img_resized = cv2.resize(img, INPUT_SIZE, interpolation=cv2.INTER_AREA)
    img_normalized = img_resized / 255.0
    img_input = np.expand_dims(img_normalized, axis=0)
    return img_input


def predict_traffic_sign(model, img_path):
    if img_path.lower().endswith('.ppm'):
        img = read_ppm_manually(img_path)
    else:
        img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    if img is None:
        return None, None, None, img

    img_input = preprocess_image(img)
    pred_probs = model.predict(img_input, verbose=0)
    pred_class_id = np.argmax(pred_probs, axis=1)[0]
    pred_confidence = round(pred_probs[0][pred_class_id] * 100, 2)
    pred_class_name = CLASS_NAMES[pred_class_id]

    return pred_class_id, pred_class_name, pred_confidence, img


# ===================== 3. è§£å†³ä¸­æ–‡æ˜¾ç¤º+æ–‡å­—å®Œæ•´çš„æ ¸å¿ƒå‡½æ•° =====================
def draw_chinese_text(img, text, pos=(10, 30), font_size=20, color=(0, 255, 0)):
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb)
    draw = ImageDraw.Draw(pil_img)

    try:
        font = ImageFont.truetype(FONT_PATH, font_size, encoding="utf-8")
    except:
        print(" ä¸­æ–‡å­—ä½“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½æ— æ³•æ˜¾ç¤ºä¸­æ–‡ï¼‰")
        font = ImageFont.load_default()

    img_w, img_h = pil_img.size
    text_lines = []
    current_line = ""
    for char in text:
        line_width = draw.textlength(current_line + char, font=font)
        if line_width > (img_w - pos[0] - 20):
            text_lines.append(current_line)
            current_line = char
        else:
            current_line += char
    if current_line:
        text_lines.append(current_line)

    y_offset = pos[1]
    for line in text_lines:
        if y_offset > (img_h - font_size - 10):
            break
        draw.text((pos[0], y_offset), line, font=font, fill=(color[2], color[1], color[0]))
        y_offset += (font_size + 5)

    img_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    return img_bgr


# ===================== 4. æ–°å¢ï¼šæŒ‡æ ‡è®¡ç®—ä¸å¯è§†åŒ–å‡½æ•° =====================
def calculate_metrics(result_data):
    """
    è®¡ç®—è¯†åˆ«æŒ‡æ ‡
    :param result_data: åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º [æ–‡ä»¶å, ç±»åˆ«ID, ç±»åˆ«åç§°, ç½®ä¿¡åº¦]
    :return: æŒ‡æ ‡å­—å…¸ + è¯¦ç»†æ•°æ®DataFrame
    """
    df = pd.DataFrame(result_data, columns=['æ–‡ä»¶å', 'ç±»åˆ«ID', 'ç±»åˆ«åç§°', 'ç½®ä¿¡åº¦'])

    # åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
    total_images = len(df)
    confidence_scores = df['ç½®ä¿¡åº¦'].tolist()

    # ç½®ä¿¡åº¦ç»Ÿè®¡
    conf_mean = round(np.mean(confidence_scores), 2)
    conf_min = round(np.min(confidence_scores), 2)
    conf_max = round(np.max(confidence_scores), 2)
    conf_std = round(np.std(confidence_scores), 2)
    conf_median = round(np.median(confidence_scores), 2)

    # ä½ç½®ä¿¡åº¦é¢„è­¦
    low_conf_count = len(df[df['ç½®ä¿¡åº¦'] < LOW_CONFIDENCE_THRESHOLD])
    low_conf_ratio = round(low_conf_count / total_images * 100, 2)
    low_conf_files = df[df['ç½®ä¿¡åº¦'] < LOW_CONFIDENCE_THRESHOLD]['æ–‡ä»¶å'].tolist()

    # ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
    class_distribution = Counter(df['ç±»åˆ«åç§°'])
    top_class = max(class_distribution, key=class_distribution.get) if class_distribution else None
    top_class_count = class_distribution.get(top_class, 0)

    # å°è£…æŒ‡æ ‡å­—å…¸
    metrics = {
        'æ€»è¯†åˆ«å›¾åƒæ•°': total_images,
        'ç½®ä¿¡åº¦å¹³å‡å€¼': conf_mean,
        'ç½®ä¿¡åº¦æœ€å°å€¼': conf_min,
        'ç½®ä¿¡åº¦æœ€å¤§å€¼': conf_max,
        'ç½®ä¿¡åº¦æ ‡å‡†å·®': conf_std,
        'ç½®ä¿¡åº¦ä¸­ä½æ•°': conf_median,
        'ä½ç½®ä¿¡åº¦é˜ˆå€¼': LOW_CONFIDENCE_THRESHOLD,
        'ä½ç½®ä¿¡åº¦å›¾åƒæ•°': low_conf_count,
        'ä½ç½®ä¿¡åº¦å æ¯”(%)': low_conf_ratio,
        'è¯†åˆ«æœ€å¤šçš„ç±»åˆ«': top_class,
        'è¯†åˆ«æœ€å¤šç±»åˆ«çš„æ•°é‡': top_class_count,
        'è¯†åˆ«ç±»åˆ«æ€»æ•°': len(class_distribution)
    }

    return metrics, df, low_conf_files


def plot_metrics_visualization(metrics, df):
    """ç»˜åˆ¶æŒ‡æ ‡å¯è§†åŒ–å›¾è¡¨"""
    fig = plt.figure(figsize=(16, 10))

    # å­å›¾1ï¼šç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
    ax1 = plt.subplot(2, 2, 1)
    ax1.hist(df['ç½®ä¿¡åº¦'], bins=20, color='lightgreen', edgecolor='black', alpha=0.7)
    ax1.axvline(metrics['ç½®ä¿¡åº¦å¹³å‡å€¼'], color='red', linestyle='--', label=f'å¹³å‡å€¼ï¼š{metrics["ç½®ä¿¡åº¦å¹³å‡å€¼"]}%')
    ax1.axvline(LOW_CONFIDENCE_THRESHOLD, color='orange', linestyle='--',
                label=f'ä½ç½®ä¿¡é˜ˆå€¼ï¼š{LOW_CONFIDENCE_THRESHOLD}%')
    ax1.set_xlabel('è¯†åˆ«ç½®ä¿¡åº¦ï¼ˆ%ï¼‰')
    ax1.set_ylabel('å›¾åƒæ•°é‡')
    ax1.set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
    ax1.legend()
    ax1.grid(axis='y', alpha=0.3)

    # å­å›¾2ï¼šç±»åˆ«è¯†åˆ«æ•°é‡TOP10
    ax2 = plt.subplot(2, 2, 2)
    class_dist = Counter(df['ç±»åˆ«åç§°'])
    top10_classes = dict(sorted(class_dist.items(), key=lambda x: x[1], reverse=True)[:10])
    ax2.barh(list(top10_classes.keys()), list(top10_classes.values()), color='skyblue')
    ax2.set_xlabel('è¯†åˆ«æ•°é‡')
    ax2.set_title('è¯†åˆ«æ•°é‡TOP10ç±»åˆ«')
    ax2.grid(axis='x', alpha=0.3)

    # å­å›¾3ï¼šå…³é”®æŒ‡æ ‡æ±‡æ€»ï¼ˆæ–‡æœ¬ï¼‰
    ax3 = plt.subplot(2, 2, 3)
    ax3.axis('off')
    metrics_text = f"""
    æ‰¹é‡è¯†åˆ«æ ¸å¿ƒæŒ‡æ ‡æ±‡æ€»
    --------------------
    æ€»è¯†åˆ«å›¾åƒæ•°ï¼š{metrics['æ€»è¯†åˆ«å›¾åƒæ•°']}
    ç½®ä¿¡åº¦ç»Ÿè®¡ï¼š
      å¹³å‡å€¼ï¼š{metrics['ç½®ä¿¡åº¦å¹³å‡å€¼']}%
      æœ€å°å€¼ï¼š{metrics['ç½®ä¿¡åº¦æœ€å°å€¼']}%
      æœ€å¤§å€¼ï¼š{metrics['ç½®ä¿¡åº¦æœ€å¤§å€¼']}%
      æ ‡å‡†å·®ï¼š{metrics['ç½®ä¿¡åº¦æ ‡å‡†å·®']}%
      ä¸­ä½æ•°ï¼š{metrics['ç½®ä¿¡åº¦ä¸­ä½æ•°']}%
    ä½ç½®ä¿¡åº¦é¢„è­¦ï¼š
      é˜ˆå€¼ï¼š{metrics['ä½ç½®ä¿¡åº¦é˜ˆå€¼']}%
      æ•°é‡ï¼š{metrics['ä½ç½®ä¿¡åº¦å›¾åƒæ•°']}
      å æ¯”ï¼š{metrics['ä½ç½®ä¿¡åº¦å æ¯”(%)']}%
    ç±»åˆ«åˆ†å¸ƒï¼š
      è¯†åˆ«ç±»åˆ«æ€»æ•°ï¼š{metrics['è¯†åˆ«ç±»åˆ«æ€»æ•°']}
      è¯†åˆ«æœ€å¤šç±»åˆ«ï¼š{metrics['è¯†åˆ«æœ€å¤šçš„ç±»åˆ«']}ï¼ˆ{metrics['è¯†åˆ«æœ€å¤šç±»åˆ«çš„æ•°é‡']}å¼ ï¼‰
    """
    ax3.text(0.05, 0.95, metrics_text, transform=ax3.transAxes, fontsize=11,
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))

    # å­å›¾4ï¼šä½ç½®ä¿¡åº¦å æ¯”é¥¼å›¾
    ax4 = plt.subplot(2, 2, 4)
    low_conf = metrics['ä½ç½®ä¿¡åº¦å›¾åƒæ•°']
    high_conf = metrics['æ€»è¯†åˆ«å›¾åƒæ•°'] - low_conf
    labels = [f'é«˜ç½®ä¿¡åº¦ï¼ˆâ‰¥{LOW_CONFIDENCE_THRESHOLD}%ï¼‰', f'ä½ç½®ä¿¡åº¦ï¼ˆ<{LOW_CONFIDENCE_THRESHOLD}%ï¼‰']
    sizes = [high_conf, low_conf]
    colors = ['#66b3ff', '#ff9999']
    explode = (0, 0.1)  # çªå‡ºä½ç½®ä¿¡åº¦éƒ¨åˆ†
    ax4.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
            shadow=True, startangle=90)
    ax4.set_title('ç½®ä¿¡åº¦ç­‰çº§åˆ†å¸ƒ')

    plt.tight_layout()
    plt.savefig(PLOT_SAVE_PATH, dpi=150, bbox_inches='tight')
    print(f"\n æŒ‡æ ‡å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³ï¼š{PLOT_SAVE_PATH}")
    plt.show()


def save_metrics_report(metrics, df, low_conf_files):
    """ä¿å­˜æŒ‡æ ‡æŠ¥å‘Šï¼ˆCSV+æ–‡æœ¬ï¼‰"""
    # ä¿å­˜è¯¦ç»†æ•°æ®CSV
    df['ä½ç½®ä¿¡åº¦é¢„è­¦'] = df['ç½®ä¿¡åº¦'] < LOW_CONFIDENCE_THRESHOLD
    df.to_csv(REPORT_SAVE_PATH, index=False, encoding='utf-8-sig')
    print(f" è¯¦ç»†è¯†åˆ«æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š{REPORT_SAVE_PATH}")

    # ä¿å­˜æŒ‡æ ‡æ±‡æ€»æ–‡æœ¬
    with open(METRICS_TXT_PATH, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("æ‰¹é‡äº¤é€šæ ‡å¿—è¯†åˆ«æŒ‡æ ‡æ±‡æ€»æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")

        f.write("1. åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡\n")
        f.write(f"   æ€»è¯†åˆ«å›¾åƒæ•°ï¼š{metrics['æ€»è¯†åˆ«å›¾åƒæ•°']}\n")
        f.write(f"   è¯†åˆ«æˆåŠŸæ•°ï¼š{metrics['æ€»è¯†åˆ«å›¾åƒæ•°']}\n")

        f.write("\n2. ç½®ä¿¡åº¦ç»Ÿè®¡æŒ‡æ ‡\n")
        f.write(f"   å¹³å‡å€¼ï¼š{metrics['ç½®ä¿¡åº¦å¹³å‡å€¼']}%\n")
        f.write(f"   æœ€å°å€¼ï¼š{metrics['ç½®ä¿¡åº¦æœ€å°å€¼']}%\n")
        f.write(f"   æœ€å¤§å€¼ï¼š{metrics['ç½®ä¿¡åº¦æœ€å¤§å€¼']}%\n")
        f.write(f"   æ ‡å‡†å·®ï¼š{metrics['ç½®ä¿¡åº¦æ ‡å‡†å·®']}%\n")
        f.write(f"   ä¸­ä½æ•°ï¼š{metrics['ç½®ä¿¡åº¦ä¸­ä½æ•°']}%\n")

        f.write("\n3. ä½ç½®ä¿¡åº¦é¢„è­¦æŒ‡æ ‡\n")
        f.write(f"   é¢„è­¦é˜ˆå€¼ï¼š{metrics['ä½ç½®ä¿¡åº¦é˜ˆå€¼']}%\n")
        f.write(f"   é¢„è­¦æ•°é‡ï¼š{metrics['ä½ç½®ä¿¡åº¦å›¾åƒæ•°']}\n")
        f.write(f"   é¢„è­¦å æ¯”ï¼š{metrics['ä½ç½®ä¿¡åº¦å æ¯”(%)']}%\n")
        if low_conf_files:
            f.write(f"   é¢„è­¦æ–‡ä»¶åˆ—è¡¨ï¼š{', '.join(low_conf_files)}\n")

        f.write("\n4. ç±»åˆ«åˆ†å¸ƒæŒ‡æ ‡\n")
        f.write(f"   è¯†åˆ«ç±»åˆ«æ€»æ•°ï¼š{metrics['è¯†åˆ«ç±»åˆ«æ€»æ•°']}\n")
        f.write(f"   è¯†åˆ«æœ€å¤šçš„ç±»åˆ«ï¼š{metrics['è¯†åˆ«æœ€å¤šçš„ç±»åˆ«']}ï¼ˆ{metrics['è¯†åˆ«æœ€å¤šç±»åˆ«çš„æ•°é‡']}å¼ ï¼‰\n")

        f.write("\n5. è´¨é‡è¯„ä¼°ç»“è®º\n")
        if metrics['ä½ç½®ä¿¡åº¦å æ¯”(%)'] < 10:
            f.write("    è¯†åˆ«è´¨é‡ä¼˜ç§€ï¼šä½ç½®ä¿¡åº¦å›¾åƒå æ¯”ä½äº10%\n")
        elif metrics['ä½ç½®ä¿¡åº¦å æ¯”(%)'] < 20:
            f.write("     è¯†åˆ«è´¨é‡è‰¯å¥½ï¼šä½ç½®ä¿¡åº¦å›¾åƒå æ¯”10%-20%\n")
        else:
            f.write("    è¯†åˆ«è´¨é‡è¾ƒå·®ï¼šä½ç½®ä¿¡åº¦å›¾åƒå æ¯”é«˜äº20%ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹æˆ–å›¾åƒè´¨é‡\n")

    print(f" æŒ‡æ ‡æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š{METRICS_TXT_PATH}")


# ===================== 5. æ‰¹é‡å¤„ç†æ ¸å¿ƒå‡½æ•°ï¼ˆæ–°å¢æŒ‡æ ‡è®¡ç®—ï¼‰ =====================
def batch_process(model):
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)

    total_count = 0
    success_count = 0
    fail_list = []
    result_data = []  # å­˜å‚¨è¯†åˆ«ç»“æœç”¨äºæŒ‡æ ‡è®¡ç®—

    # éå†æ–‡ä»¶
    file_list = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(SUPPORTED_FORMATS)]
    if not file_list:
        print("  æœªæ‰¾åˆ°æ”¯æŒçš„å›¾åƒæ–‡ä»¶ï¼")
        return

    print(f"\n å¼€å§‹æ‰¹é‡å¤„ç† {len(file_list)} ä¸ªæ–‡ä»¶...")

    for file_name in file_list:
        total_count += 1
        img_path = os.path.join(INPUT_FOLDER, file_name)
        print(f"\næ­£åœ¨å¤„ç†ï¼š{file_name}")

        class_id, class_name, confidence, img = predict_traffic_sign(model, img_path)

        if class_id is not None and img is not None:
            success_count += 1
            result_data.append([file_name, class_id, class_name, confidence])

            # æ‰“å°å•å¼ è¯†åˆ«ç»“æœ
            print(f"  ç±»åˆ«IDï¼š{class_id}")
            print(f"  ç±»åˆ«åç§°ï¼š{class_name}")
            print(f"  ç½®ä¿¡åº¦ï¼š{confidence}%")
            if confidence < LOW_CONFIDENCE_THRESHOLD:
                print(f"    ä½ç½®ä¿¡åº¦é¢„è­¦ï¼ï¼ˆä½äº{LOW_CONFIDENCE_THRESHOLD}%ï¼‰")

            # å¤„ç†å¹¶ä¿å­˜å›¾åƒ
            img_show = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            base_width = 500
            h, w = img_show.shape[:2]
            scale = base_width / w
            new_h = int(h * scale)
            img_show = cv2.resize(img_show, (base_width, new_h), interpolation=cv2.INTER_CUBIC)

            # æ‹¼æ¥æ–‡å­—ï¼ˆæ–°å¢ä½ç½®ä¿¡åº¦é¢„è­¦æ ‡è¯†ï¼‰
            warn_tag = " ä½ç½®ä¿¡åº¦ " if confidence < LOW_CONFIDENCE_THRESHOLD else ""
            text = f"{warn_tag}æ–‡ä»¶åï¼š{file_name} | ID:{class_id} | ç±»åˆ«ï¼š{class_name} | ç½®ä¿¡åº¦ï¼š{confidence}%"

            # ä½ç½®ä¿¡åº¦æ–‡å­—ç”¨çº¢è‰²æ ‡æ³¨
            text_color = (0, 0, 255) if confidence < LOW_CONFIDENCE_THRESHOLD else (0, 255, 0)
            img_show = draw_chinese_text(
                img_show,
                text,
                pos=(15, 30),
                font_size=22,
                color=text_color
            )

            save_name = f"{os.path.splitext(file_name)[0]}_è¯†åˆ«ç»“æœ.png"
            save_path = os.path.join(OUTPUT_FOLDER, save_name)
            cv2.imwrite(save_path, img_show)
            print(f"  ç»“æœå›¾å·²ä¿å­˜è‡³ï¼š{save_path}")
        else:
            fail_list.append(file_name)
            print(f"  å¤„ç†å¤±è´¥ï¼š{file_name}")

    # è¾“å‡ºåŸºç¡€ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("æ‰¹é‡å¤„ç†å®Œæˆï¼åŸºç¡€ç»Ÿè®¡ç»“æœï¼š")
    print(f"æ€»æ‰«ææ–‡ä»¶æ•°ï¼š{total_count}")
    print(f"æˆåŠŸè¯†åˆ«æ•°ï¼š{success_count}")
    print(f"å¤„ç†å¤±è´¥æ•°ï¼š{len(fail_list)}")
    if fail_list:
        print(f"å¤±è´¥æ–‡ä»¶åˆ—è¡¨ï¼š{fail_list}")
    print("=" * 60)

    # è®¡ç®—å¹¶ä¿å­˜è¯¦ç»†æŒ‡æ ‡
    if result_data:
        print("\n å¼€å§‹è®¡ç®—è¯†åˆ«æŒ‡æ ‡...")
        metrics, df, low_conf_files = calculate_metrics(result_data)

        # è¾“å‡ºå…³é”®æŒ‡æ ‡
        print("\n" + "=" * 60)
        print("æ ¸å¿ƒè¯†åˆ«æŒ‡æ ‡æ±‡æ€»ï¼š")
        print(f"ç½®ä¿¡åº¦å¹³å‡å€¼ï¼š{metrics['ç½®ä¿¡åº¦å¹³å‡å€¼']}%")
        print(f"ä½ç½®ä¿¡åº¦å›¾åƒæ•°ï¼š{metrics['ä½ç½®ä¿¡åº¦å›¾åƒæ•°']}ï¼ˆå æ¯”{metrics['ä½ç½®ä¿¡åº¦å æ¯”(%)']}%ï¼‰")
        print(f"è¯†åˆ«ç±»åˆ«æ€»æ•°ï¼š{metrics['è¯†åˆ«ç±»åˆ«æ€»æ•°']}")
        print("=" * 60)

        # ä¿å­˜æŠ¥å‘Š
        save_metrics_report(metrics, df, low_conf_files)

        # ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨
        plot_metrics_visualization(metrics, df)

    # æ˜¾ç¤ºç¤ºä¾‹å›¾åƒ
    if success_count > 0:
        success_files = [f for f in os.listdir(OUTPUT_FOLDER) if f.endswith('_è¯†åˆ«ç»“æœ.png')]
        if success_files:
            last_file = success_files[-1]
            last_path = os.path.join(OUTPUT_FOLDER, last_file)
            last_img = cv2.imread(last_path)
            if last_img is not None:
                cv2.namedWindow("ğŸš¦ æ‰¹é‡å¤„ç†ç¤ºä¾‹ç»“æœï¼ˆæŒ‰ä»»æ„é”®å…³é—­ï¼‰", cv2.WINDOW_NORMAL)
                cv2.imshow("ğŸš¦ æ‰¹é‡å¤„ç†ç¤ºä¾‹ç»“æœï¼ˆæŒ‰ä»»æ„é”®å…³é—­ï¼‰", last_img)
                cv2.waitKey(0)
                cv2.destroyAllWindows()


# ===================== 6. ä¸»å‡½æ•° =====================
def main():
    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

    # åŠ è½½æ¨¡å‹
    try:
        model = keras.models.load_model(MODEL_PATH)
        print(" æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f" æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        return

    # æ‰§è¡Œæ‰¹é‡å¤„ç†
    print(f"\n å¾…å¤„ç†æ–‡ä»¶å¤¹ï¼š{INPUT_FOLDER}")
    print(f" æ”¯æŒæ ¼å¼ï¼š{SUPPORTED_FORMATS}")
    print(f" ä½ç½®ä¿¡åº¦é¢„è­¦é˜ˆå€¼ï¼š{LOW_CONFIDENCE_THRESHOLD}%")
    batch_process(model)


if __name__ == "__main__":
    # å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œå–æ¶ˆæ³¨é‡Šï¼‰
    # os.system("pip install pandas matplotlib numpy")
    main()
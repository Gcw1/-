import cv2
import numpy as np
from tensorflow import keras
import os
from PIL import Image, ImageDraw, ImageFont
import numpy as np

# ===================== 1. æ ¸å¿ƒé…ç½®å‚æ•° =====================
MODEL_PATH = r"D:\OneDrive\æ¡Œé¢\Traffic_Sign_Classify\Mymodle\traffic_sign_model.h5"
CLASS_NAMES = [
    "é™é€Ÿ20km/h", "é™é€Ÿ30km/h", "é™é€Ÿ50km/h", "é™é€Ÿ60km/h", "é™é€Ÿ70km/h",
    "é™é€Ÿ80km/h", "è§£é™¤é™é€Ÿ80km/h", "é™é€Ÿ100km/h", "é™é€Ÿ120km/h", "ç¦æ­¢è¶…è½¦",
    "ç¦æ­¢å¤§å‹è½¦è¾†è¶…è½¦", "å‰æ–¹è·¯å£", "ä¼˜å…ˆé€šè¡Œ", "è®©è¡Œ", "åœè½¦è®©è¡Œ",
    "ç¦æ­¢é€šè¡Œ", "ç¦æ­¢å¤§å‹è½¦è¾†è¿›å…¥", "ç¦æ­¢é©¶å…¥", "è­¦å‘Š", "æ€¥è½¬å¼¯ï¼ˆå·¦ï¼‰",
    "æ€¥è½¬å¼¯ï¼ˆå³ï¼‰", "è¿ç»­å¼¯é“", "è·¯é¢é¢ ç°¸", "è·¯é¢æ¹¿æ»‘", "é“è·¯å˜çª„ï¼ˆå³ï¼‰",
    "æ–½å·¥", "äº¤é€šä¿¡å·ç¯", "è¡Œäºº", "å„¿ç«¥", "è‡ªè¡Œè½¦",
    "é“è·¯ç»“å†°", "é‡ç”ŸåŠ¨ç‰©", "è§£é™¤é™é€Ÿ/è¶…è½¦", "å³è½¬", "å·¦è½¬",
    "ç›´è¡Œ", "ç›´è¡Œ+å³è½¬", "ç›´è¡Œ+å·¦è½¬", "é å³è¡Œé©¶", "é å·¦è¡Œé©¶",
    "ç¯å²›è¡Œé©¶", "è§£é™¤ç¦æ­¢è¶…è½¦", "è§£é™¤ç¦æ­¢å¤§å‹è½¦è¾†è¶…è½¦"
]
INPUT_SIZE = (32, 32)
# ä¸­æ–‡æ˜¾ç¤ºæ‰€éœ€å­—ä½“è·¯å¾„ï¼ˆæ›¿æ¢ä¸ºä½ ç”µè„‘ä¸­çš„ä¸­æ–‡å­—ä½“è·¯å¾„ï¼Œä¾‹å¦‚å¾®è½¯é›…é»‘ï¼‰
FONT_PATH = r"C:\Windows\Fonts\msyh.ttc"  # ç³»ç»Ÿé»˜è®¤å¾®è½¯é›…é»‘è·¯å¾„


# ===================== 2. å·¥å…·å‡½æ•°å®šä¹‰ =====================
def read_ppm_manually(file_path):
    try:
        with open(file_path, 'rb') as f:
            header = f.readline().decode('ascii').strip()
            if header not in ('P3', 'P6'):
                return None
            while True:
                line = f.readline().decode('ascii').strip()
                if not line.startswith('#'):
                    break
            width, height = map(int, line.split())
            max_val = int(f.readline().decode('ascii').strip())
            if header == 'P6':
                data = f.read(width * height * 3)
                img = np.frombuffer(data, dtype=np.uint8).reshape((height, width, 3))
            else:
                data = []
                while len(data) < width * height * 3:
                    data += list(map(int, f.readline().decode('ascii').split()))
                img = np.array(data, dtype=np.uint8).reshape((height, width, 3))
        return img
    except Exception as e:
        print(f"è¯»å–{file_path}å¤±è´¥ï¼š{e}")
        return None


def preprocess_image(img):
    img_resized = cv2.resize(img, INPUT_SIZE, interpolation=cv2.INTER_AREA)
    img_normalized = img_resized / 255.0
    img_input = np.expand_dims(img_normalized, axis=0)
    return img_input


def predict_traffic_sign(model, img_path):
    if img_path.lower().endswith('.ppm'):
        img = read_ppm_manually(img_path)
    else:
        img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    if img is None:
        return None, None, None, img

    img_input = preprocess_image(img)
    pred_probs = model.predict(img_input, verbose=0)
    pred_class_id = np.argmax(pred_probs, axis=1)[0]
    pred_confidence = round(pred_probs[0][pred_class_id] * 100, 2)
    pred_class_name = CLASS_NAMES[pred_class_id]

    return pred_class_id, pred_class_name, pred_confidence, img


# ===================== 3. è§£å†³ä¸­æ–‡æ˜¾ç¤º+æ–‡å­—å®Œæ•´çš„æ ¸å¿ƒå‡½æ•° =====================
def draw_chinese_text(img, text, pos=(10, 30), font_size=20, color=(0, 255, 0)):
    """
    ä½¿ç”¨PILç»˜åˆ¶ä¸­æ–‡ï¼ˆè§£å†³OpenCVä¸æ”¯æŒä¸­æ–‡çš„é—®é¢˜ï¼‰
    :param img: BGRæ ¼å¼å›¾åƒ
    :param text: è¦æ˜¾ç¤ºçš„æ–‡å­—ï¼ˆå«ä¸­æ–‡ï¼‰
    :param pos: æ–‡å­—èµ·å§‹ä½ç½®
    :param font_size: å­—ä½“å¤§å°
    :param color: æ–‡å­—é¢œè‰²ï¼ˆBGRæ ¼å¼ï¼‰
    :return: ç»˜åˆ¶åçš„BGRå›¾åƒ
    """
    # 1. è½¬æ¢ä¸ºPILå›¾åƒï¼ˆRGBæ ¼å¼ï¼‰
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb)
    draw = ImageDraw.Draw(pil_img)

    # 2. åŠ è½½ä¸­æ–‡å­—ä½“
    try:
        font = ImageFont.truetype(FONT_PATH, font_size, encoding="utf-8")
    except:
        print("âš ï¸ ä¸­æ–‡å­—ä½“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½æ— æ³•æ˜¾ç¤ºä¸­æ–‡ï¼‰")
        font = ImageFont.load_default()

    # 3. æ‹†åˆ†æ–‡å­—ä¸ºå¤šè¡Œï¼ˆé¿å…è¶…å‡ºå›¾åƒï¼‰
    img_w, img_h = pil_img.size
    text_lines = []
    current_line = ""
    for char in text:
        # ä¼°ç®—å½“å‰è¡Œå®½åº¦
        line_width = draw.textlength(current_line + char, font=font)
        if line_width > (img_w - pos[0] - 20):  # é¢„ç•™è¾¹è·
            text_lines.append(current_line)
            current_line = char
        else:
            current_line += char
    if current_line:
        text_lines.append(current_line)

    # 4. é€è¡Œç»˜åˆ¶æ–‡å­—
    y_offset = pos[1]
    for line in text_lines:
        if y_offset > (img_h - font_size - 10):  # é¿å…è¶…å‡ºå›¾åƒé«˜åº¦
            break
        draw.text((pos[0], y_offset), line, font=font, fill=(color[2], color[1], color[0]))  # PILæ˜¯RGBæ ¼å¼
        y_offset += (font_size + 5)  # è¡Œé—´è·

    # 5. è½¬æ¢å›BGRæ ¼å¼
    img_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    return img_bgr


# ===================== 4. ä¸»å‡½æ•° =====================
def main():
    try:
        model = keras.models.load_model(MODEL_PATH)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        return

    TEST_IMG_PATH = r"D:\OneDrive\æ¡Œé¢\æ–°å»ºæ–‡ä»¶å¤¹ (4)\1.png"
    class_id, class_name, confidence, img = predict_traffic_sign(model, TEST_IMG_PATH)

    if class_id is not None:
        print("\nğŸ“Œ å•å¼ å›¾åƒè¯†åˆ«ç»“æœï¼š")
        print(f"  å›¾åƒè·¯å¾„ï¼š{TEST_IMG_PATH}")
        print(f"  ç±»åˆ«IDï¼š{class_id}")
        print(f"  ç±»åˆ«åç§°ï¼š{class_name}")
        print(f"  ç½®ä¿¡åº¦ï¼š{confidence}%")

        if img is not None:
            # è°ƒæ•´å›¾åƒåŸºç¡€å°ºå¯¸
            img_show = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            base_width = 500
            h, w = img_show.shape[:2]
            scale = base_width / w
            new_h = int(h * scale)
            img_show = cv2.resize(img_show, (base_width, new_h), interpolation=cv2.INTER_CUBIC)

            # æ‹¼æ¥è¯†åˆ«æ–‡å­—ï¼ˆå«ä¸­æ–‡ï¼‰
            text = f"ID:{class_id} | ç±»åˆ«ï¼š{class_name} | ç½®ä¿¡åº¦ï¼š{confidence}%"

            # ç»˜åˆ¶ä¸­æ–‡æ–‡å­—ï¼ˆè§£å†³æ˜¾ç¤ºé—®é¢˜ï¼‰
            img_show = draw_chinese_text(
                img_show,
                text,
                pos=(15, 30),
                font_size=22,
                color=(0, 255, 0)
            )

            # ä¿å­˜é«˜æ¸…ç»“æœå›¾
            save_path = r"D:\OneDrive\æ¡Œé¢\æ–°å»ºæ–‡ä»¶å¤¹ (4)\è¯†åˆ«ç»“æœ_ä¸­æ–‡å®Œæ•´ç‰ˆ.png"
            cv2.imwrite(save_path, img_show)
            print(f"ğŸ“¸ ç»“æœå›¾å·²ä¿å­˜è‡³ï¼š{save_path}")

            # æ˜¾ç¤ºå›¾åƒ
            cv2.namedWindow("ğŸš¦ äº¤é€šæ ‡å¿—è¯†åˆ«ç»“æœï¼ˆä¸­æ–‡å®Œæ•´ï¼‰", cv2.WINDOW_NORMAL)
            cv2.imshow("ğŸš¦ äº¤é€šæ ‡å¿—è¯†åˆ«ç»“æœï¼ˆä¸­æ–‡å®Œæ•´ï¼‰", img_show)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
    else:
        print(f"\nâŒ å›¾åƒè¯»å–å¤±è´¥ï¼š{TEST_IMG_PATH}")


if __name__ == "__main__":
    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    main()